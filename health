from google.colab import files
uploaded = files.upload()
CSV_PATH = list(uploaded.keys())[0]

import warnings, json
warnings.filterwarnings("ignore")
import numpy as np, pandas as pd, matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier

RANDOM_STATE = 42
TEST_SIZE = 0.2
N_JOBS = -1

# Load CSV
df = pd.read_csv(CSV_PATH)
drop_like = [c for c in df.columns if any(k in c.lower() for k in ["url","image","img","photo","link","thumbnail"])]
if drop_like: df = df.drop(columns=drop_like)

# Convert numeric
num_cols_all = ["calories","protein_g","carbs_g","fat_g","fiber_g","sugar_g","sodium_mg","cholesterol_mg","serving_size_g","prep_time_min","cook_time_min","rating"]
for c in num_cols_all:
    if c in df.columns: df[c] = pd.to_numeric(df[c], errors="coerce")

# Convert health column
if "is_healthy" in df.columns:
    if df["is_healthy"].dtype == object:
        df["is_healthy"] = df["is_healthy"].astype(str).str.strip().str.lower().map({"yes":1,"true":1,"1":1,"no":0,"false":0,"0":0})
    df["is_healthy"] = pd.to_numeric(df["is_healthy"], errors="coerce").astype("Int64")

# Categorical and numeric
cat_cols = [c for c in ["cuisine","meal_type","diet_type","cooking_method"] if c in df.columns]
num_cols = [c for c in ["calories","protein_g","carbs_g","fat_g","fiber_g","sugar_g","sodium_mg","cholesterol_mg","serving_size_g","prep_time_min","cook_time_min"] if c in df.columns]

# Derived features
if set(["calories","serving_size_g"]).issubset(df.columns):
    df["cal_per_g"] = df["calories"] / df["serving_size_g"].replace(0, np.nan)
    num_cols.append("cal_per_g")
if set(["protein_g","carbs_g","fat_g"]).issubset(df.columns):
    total = (df["protein_g"].fillna(0)+df["carbs_g"].fillna(0)+df["fat_g"].fillna(0)).replace(0, np.nan)
    df["protein_ratio"] = df["protein_g"]/total
    df["carb_ratio"]    = df["carbs_g"]/total
    df["fat_ratio"]     = df["fat_g"]/total
    num_cols += ["protein_ratio","carb_ratio","fat_ratio"]

feature_cols = cat_cols + num_cols
preprocessor = ColumnTransformer([("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols),
                                  ("num","passthrough",num_cols)], remainder="drop")

# --- Correlation Graph ---
plt.figure(figsize=(10,6))
corr = df[num_cols].corr()
plt.imshow(corr, cmap="coolwarm", interpolation="none")
plt.colorbar()
plt.title("Feature Correlation Heatmap")
plt.xticks(range(len(num_cols)), num_cols, rotation=90)
plt.yticks(range(len(num_cols)), num_cols)
plt.show()

# --- REGRESSION ---
if "rating" in df.columns:
    d = df.dropna(subset=["rating"]).copy()
    Xr, yr = d[feature_cols], d["rating"].astype(float)
    Xtr, Xte, ytr, yte = train_test_split(Xr, yr, test_size=TEST_SIZE, random_state=RANDOM_STATE)
    models = {"LinearRegression":LinearRegression(),"RandomForestRegressor":RandomForestRegressor(n_estimators=400,random_state=RANDOM_STATE,n_jobs=N_JOBS),"GradientBoostingRegressor":GradientBoostingRegressor(random_state=RANDOM_STATE)}
    res = []
    fitted = {}
    for n,m in models.items():
        p = Pipeline([("prep",preprocessor),("model",m)])
        p.fit(Xtr,ytr)
        pr = p.predict(Xte)
        rmse = np.sqrt(mean_squared_error(yte,pr))
        res.append({"Model":n,"R2":r2_score(yte,pr),"MAE":mean_absolute_error(yte,pr),"RMSE":rmse})
        fitted[n] = p
    results_reg = pd.DataFrame(res)
    print("\n--- Regression Results (Rating) ---")
    print(results_reg)

    best_reg = results_reg.sort_values("R2",ascending=False).iloc[0]["Model"]
    best_pipe = fitted[best_reg]
    pred = best_pipe.predict(Xte)

    plt.figure(figsize=(6,6))
    plt.scatter(yte, pred, alpha=0.6)
    plt.xlabel("Actual Rating")
    plt.ylabel("Predicted Rating")
    plt.title(f"Actual vs Predicted Ratings ({best_reg})")
    plt.plot([yte.min(), yte.max()], [yte.min(), yte.max()], "r--")
    plt.show()

    if "Regressor" in best_reg:
        model = best_pipe.named_steps["model"]
        if hasattr(model,"feature_importances_"):
            ohe = best_pipe.named_steps["prep"].named_transformers_["cat"]
            features = list(ohe.get_feature_names_out(cat_cols)) + num_cols
            importances = model.feature_importances_
            idx = np.argsort(importances)[-10:]
            plt.figure(figsize=(7,5))
            plt.barh(np.array(features)[idx], importances[idx])
            plt.title(f"Top Feature Importances ({best_reg})")
            plt.show()

# --- CLASSIFICATION ---
if "is_healthy" in df.columns:
    d = df.dropna(subset=["is_healthy"]).copy()
    Xc, yc = d[feature_cols], d["is_healthy"].astype(int)
    Xtr, Xte, ytr, yte = train_test_split(Xc, yc, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=yc)
    models = {"LogisticRegression":LogisticRegression(max_iter=500),
              "RandomForestClassifier":RandomForestClassifier(n_estimators=400,random_state=RANDOM_STATE,n_jobs=N_JOBS),
              "GradientBoostingClassifier":GradientBoostingClassifier(random_state=RANDOM_STATE)}
    res = []
    fitted = {}
    for n,m in models.items():
        p = Pipeline([("prep",preprocessor),("model",m)])
        p.fit(Xtr,ytr)
        pr = p.predict(Xte)
        try: auc = roc_auc_score(yte,p.predict_proba(Xte)[:,1])
        except: auc = np.nan
        res.append({"Model":n,"Accuracy":accuracy_score(yte,pr),"F1":f1_score(yte,pr),"AUC":auc})
        fitted[n] = p
    results_clf = pd.DataFrame(res)
    print("\n--- Classification Results (is_healthy) ---")
    print(results_clf)

    best_clf = results_clf.sort_values("F1",ascending=False).iloc[0]["Model"]
    best_pipe = fitted[best_clf]
    cm = confusion_matrix(yte, best_pipe.predict(Xte))
    plt.imshow(cm, cmap="Blues")
    plt.title(f"Confusion Matrix ({best_clf})")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    for (i, j), v in np.ndenumerate(cm):
        plt.text(j, i, str(v), ha="center", va="center")
    plt.show()

    if "Classifier" in best_clf:
        model = best_pipe.named_steps["model"]
        if hasattr(model,"feature_importances_"):
            ohe = best_pipe.named_steps["prep"].named_transformers_["cat"]
            features = list(ohe.get_feature_names_out(cat_cols)) + num_cols
            importances = model.feature_importances_
            idx = np.argsort(importances)[-10:]
            plt.figure(figsize=(7,5))
            plt.barh(np.array(features)[idx], importances[idx])
            plt.title(f"Top Feature Importances ({best_clf})")
            plt.show()

# --- RESEARCH QUESTION & FINDINGS ---
print("\n--- RESEARCH QUESTION ---")
print("How do meal type, cuisine, and nutritional composition (calories, protein, carbs, fat, etc.) influence meal ratings and healthiness, and can we predict them using data analytics?")

print("\n--- FINDINGS ---")
if "rating" in df.columns:
    best_reg = results_reg.sort_values("R2",ascending=False).iloc[0]
    print(f"Best Regression Model: {best_reg['Model']} | RÂ²={best_reg['R2']:.3f}, RMSE={best_reg['RMSE']:.3f}")
if "is_healthy" in df.columns:
    best_clf = results_clf.sort_values("F1",ascending=False).iloc[0]
    print(f"Best Classification Model: {best_clf['Model']} | Accuracy={best_clf['Accuracy']:.3f}, F1={best_clf['F1']:.3f}")
print("\nThis analysis shows that nutritional composition and meal types strongly influence both meal ratings and healthiness.")
print("Higher protein and lower fat ratios generally correlate with healthier meals, while balanced macronutrients improve ratings.")
print("Machine learning models confirm these relationships, successfully predicting both rating and healthiness outcomes.")
